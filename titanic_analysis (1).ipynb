{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed77670",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Impute Embarked with most frequent\u001b[39;00m\n\u001b[32m     20\u001b[39m embarked_imputer = SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmost_frequent\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEmbarked\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = embarked_imputer.fit_transform(df_clean[[\u001b[33m'\u001b[39m\u001b[33mEmbarked\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Encode categorical columns\u001b[39;00m\n\u001b[32m     24\u001b[39m label_encoders = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4308\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4310\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4515\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4516\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4517\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4522\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4524\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4527\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4528\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4529\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4530\u001b[39m     ):\n\u001b[32m   4531\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4532\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:5267\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m   5266\u001b[39m     com.require_length_match(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m-> \u001b[39m\u001b[32m5267\u001b[39m arr = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   5268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5269\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5270\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5273\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5274\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n\u001b[32m   5275\u001b[39m     warnings.warn(\n\u001b[32m   5276\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSetting an Index with object dtype into a DataFrame will stop \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5277\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minferring another dtype in a future version. Cast the Index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5280\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   5281\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\construction.py:606\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, allow_2d)\u001b[39m\n\u001b[32m    604\u001b[39m subarr = data\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     subarr = \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    608\u001b[39m         object_index\n\u001b[32m    609\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[32m    610\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[32m    611\u001b[39m     ):\n\u001b[32m    612\u001b[39m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[32m    613\u001b[39m         subarr = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1181\u001b[39m, in \u001b[36mmaybe_infer_to_datetimelike\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(value))  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m   1179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.ndim != \u001b[32m1\u001b[39m:\n\u001b[32m   1180\u001b[39m     \u001b[38;5;66;03m# Caller is responsible\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(value.ndim)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[31mValueError\u001b[39m: 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# Copy dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Drop Cabin\n",
    "df_clean.drop(columns=['Cabin'], inplace=True)\n",
    "# Impute Age with median\n",
    "age_imputer = SimpleImputer(strategy='median')\n",
    "df_clean['Age'] = age_imputer.fit_transform(df_clean[['Age']])\n",
    "# Impute Embarked with most frequent\n",
    "embarked_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_clean['Embarked'] = embarked_imputer.fit_transform(df_clean[['Embarked']])\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "categorical_cols = ['Sex', 'Embarked']\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Standardize numerical columns\n",
    "numerical_cols = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "scaler = StandardScaler()\n",
    "df_clean[numerical_cols] = scaler.fit_transform(df_clean[numerical_cols])\n",
    "\n",
    "# Remove outliers\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "\n",
    "# Visualize boxplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    sns.boxplot(y=df_clean[col], ax=axes[i//2][i%2])\n",
    "    axes[i//2][i%2].set_title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e888d4a-4784-4ba6-8529-897eca015ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Titanic Dataset Preprocessing and Analysis\n",
    "\n",
    "## Step 1: Import and Explore the Dataset\n",
    "\n",
    "The dataset consists of 891 rows and 12 columns. Key observations:\n",
    "- Missing values in `Age`, `Cabin`, and `Embarked`.\n",
    "- `Cabin` has too many missing values and was dropped.\n",
    "- Mix of categorical and numerical features.\n",
    "\n",
    "## Step 2: Handle Missing Values\n",
    "- `Age`: Imputed using the median.\n",
    "- `Embarked`: Imputed using the most frequent value.\n",
    "- `Cabin`: Dropped due to excessive missing data.\n",
    "\n",
    "## Step 3: Encode Categorical Features\n",
    "- `Sex` and `Embarked` converted to numeric using Label Encoding.\n",
    "\n",
    "## Step 4: Normalize Numerical Features\n",
    "- StandardScaler was used on `Age`, `Fare`, `SibSp`, and `Parch`.\n",
    "\n",
    "## Step 5: Outlier Detection and Removal\n",
    "- Boxplots used to visualize outliers.\n",
    "- Outliers removed using the IQR method for the 4 standardized numerical columns.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
